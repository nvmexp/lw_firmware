/******************************************************************************
 * 
 * Copyright 2010-2012,2017 Duane Merrill
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License. 
 * 
 * For more information, see our Google Code project site: 
 * http://code.google.com/p/back40computing/
 * 
 * Thanks!
 * 
 ******************************************************************************/

/******************************************************************************
 * Management of temporary device storage needed for maintaining partial
 * reductions between subsequent grids
 ******************************************************************************/

#pragma once

#include <b40c/util/error_utils.lwh>
#include <b40c/util/lwda_properties.lwh>

namespace b40c {
namespace util {

/**
 * Manages device storage needed for communicating partial reductions
 * between CTAs in subsequent grids
 */
struct Spine
{
	//---------------------------------------------------------------------
	// Members
	//---------------------------------------------------------------------
    
	// Device spine storage    
	void *d_spine;

	// Host-mapped spine storage (if so constructed)    
	void *h_spine;

	// Number of bytes backed by d_spine
	size_t spine_bytes;	
	
#ifndef __LWDACC__
    // Added for support with MODS
    Lwca::Instance* instance;
    Lwca::DeviceMemory cd_spine;
    Lwca::HostMemory ch_spine;
    Lwca::Device gpu;
#else
    // GPU d_spine was allocated on
    int gpu;
#endif

	// Whether or not the spine has a shadow spine on the host
	bool host_shadow;


	//---------------------------------------------------------------------
	// Methods
	//---------------------------------------------------------------------

	/**
	 * Constructor (device-allocated spine)
	 */
	Spine() :        
		d_spine(NULL),
		h_spine(NULL),
		spine_bytes(0),
#ifndef __LWDACC__
        instance(NULL),
#else
		gpu(LWB_ILWALID_DEVICE),
#endif
		host_shadow(false) {}
        
#ifndef __LWDACC__
    Spine(Lwca::Instance* instance) :        
		d_spine(NULL),
		h_spine(NULL),
		spine_bytes(0),
        instance(instance),
		host_shadow(false) {}
#endif


	/**
	 * Constructor
	 *
	 * @param host_shadow
	 * 		Whether or not the spine has a shadow spine on the host
	 */
	Spine(bool host_shadow) :        
		d_spine(NULL),
		h_spine(NULL),
		spine_bytes(0),
#ifndef __LWDACC__
        instance(NULL),
#else
		gpu(LWB_ILWALID_DEVICE),
#endif
		host_shadow(host_shadow) {}

    /**
	 * Deallocates and resets the spine
	 */
#ifndef __LWDACC__
	lwdaError_t HostReset()
	{
		lwdaError_t retval = lwdaSuccess;

        if (!gpu.IsValid()) return retval;

		if (d_spine) {
			// Deallocate
            cd_spine.Free();
			d_spine = NULL;
		}
		if (h_spine) {
			// Deallocate
            ch_spine.Free();
			h_spine = NULL;
		}

		spine_bytes	= 0;

		return retval;
	}
#else
	lwdaError_t HostReset()
	{
		lwdaError_t retval = lwdaSuccess;
		do {

			if (gpu == LWB_ILWALID_DEVICE) return retval;

			// Save current gpu
			int lwrrent_gpu;
			if (retval = util::B40CPerror(lwdaGetDevice(&lwrrent_gpu),
				"Spine lwdaGetDevice failed: ", __FILE__, __LINE__)) break;
#if LWDA_VERSION >= 4000
			if (retval = util::B40CPerror(lwdaSetDevice(gpu),
				"Spine lwdaSetDevice failed: ", __FILE__, __LINE__)) break;
#endif
			if (d_spine) {
				// Deallocate
				if (retval = util::B40CPerror(lwdaFree(d_spine),
					"Spine lwdaFree d_spine failed: ", __FILE__, __LINE__)) break;
				d_spine = NULL;
			}
			if (h_spine) {
				// Deallocate
				if (retval = util::B40CPerror(lwdaFreeHost((void *) h_spine),
					"Spine lwdaFreeHost h_spine failed", __FILE__, __LINE__)) break;

				h_spine = NULL;
			}

#if LWDA_VERSION >= 4000
			// Restore current gpu
			if (retval = util::B40CPerror(lwdaSetDevice(lwrrent_gpu),
				"Spine lwdaSetDevice failed: ", __FILE__, __LINE__)) break;
#endif

			gpu 			= LWB_ILWALID_DEVICE;
			spine_bytes	 	= 0;

		} while (0);

		return retval;
	}
#endif

	/**
	 * Destructor
	 */
	virtual ~Spine()
	{
		HostReset();
	}


	/**
	 * Device spine storage accessor
	 */
	void* operator()()
	{
		return d_spine;
	}


	/**
	 * Sets up the spine to accommodate the specified number of bytes.
	 * Reallocates if necessary.
	 */
#ifndef __LWDACC__
	template <typename SizeT>
	lwdaError_t Setup(SizeT problem_spine_bytes)
	{
		lwdaError_t retval = lwdaSuccess;
		do {
			// Get current gpu
            Lwca::Device lwrrent_gpu = instance->GetLwrrentDevice();

			// Check if big enough and if lives on proper GPU
			if ((problem_spine_bytes > spine_bytes) || (gpu.GetHandle() != lwrrent_gpu.GetHandle())) {

				// Deallocate if exists
				retval = HostReset();
				if (retval) break;

				// Remember device
				gpu = lwrrent_gpu;

				// Reallocate
				spine_bytes = problem_spine_bytes;

				// Allocate on device
                instance->AllocDeviceMem(spine_bytes, &cd_spine);
                d_spine = (void*)cd_spine.GetDevicePtr();

				if (host_shadow) {
					// Allocate pinned memory for h_spine
                    instance->AllocHostMem(problem_spine_bytes, &ch_spine);
                    h_spine = ch_spine.GetPtr();
				}
			}
		} while (0);

		return retval;
	}
#else
    template <typename SizeT>
	lwdaError_t Setup(SizeT problem_spine_bytes)
	{
		lwdaError_t retval = lwdaSuccess;
		do {
			// Get current gpu
			int lwrrent_gpu;
			if (retval = util::B40CPerror(lwdaGetDevice(&lwrrent_gpu),
				"Spine lwdaGetDevice failed: ", __FILE__, __LINE__)) break;

			// Check if big enough and if lives on proper GPU
			if ((problem_spine_bytes > spine_bytes) || (gpu != lwrrent_gpu)) {

				// Deallocate if exists
				if (retval = HostReset()) break;

				// Remember device
				gpu = lwrrent_gpu;

				// Reallocate
				spine_bytes = problem_spine_bytes;

				// Allocate on device
				if (retval = util::B40CPerror(lwdaMalloc((void**) &d_spine, spine_bytes),
					"Spine lwdaMalloc d_spine failed", __FILE__, __LINE__)) break;

				if (host_shadow) {
					// Allocate pinned memory for h_spine
					int flags = lwdaHostAllocMapped;
					if (retval = util::B40CPerror(lwdaHostAlloc((void **)&h_spine, problem_spine_bytes, flags),
						"Spine lwdaHostAlloc h_spine failed", __FILE__, __LINE__)) break;
				}
			}
		} while (0);

		return retval;
	}
    
	/**
	 * Syncs the shadow host spine with device spine
	 */
	lwdaError_t Sync(lwdaStream_t stream)
	{
		return lwdaMemcpyAsync(
			h_spine,
			d_spine,
			spine_bytes,
			lwdaMemcpyDeviceToHost,
			stream);
	}


	/**
	 * Syncs the shadow host spine with device spine
	 */
	lwdaError_t Sync()
	{
		return lwdaMemcpy(
			h_spine,
			d_spine,
			spine_bytes,
			lwdaMemcpyDeviceToHost);
	}
#endif

};

} // namespace util
} // namespace b40c

